{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "############   IMPORTS   ##############\n",
        "import string\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qM04Uk5xsVyb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############   SCRAPING FOR DATA   ##############\n",
        "playersStatsTable = []\n",
        "\n",
        "# scrape through players on https://www.basketball-reference.com/players/a-z, exclude players after 2015\n",
        "count = 0\n",
        "# iterate through each letter of directory pages\n",
        "for letter in string.ascii_lowercase:\n",
        "    bBallReferenceUrl = \"https://www.basketball-reference.com/players/\" + letter\n",
        "    directoryReponse = requests.get(bBallReferenceUrl)\n",
        "    \n",
        "    if directoryReponse.ok:\n",
        "      # find rows containing info of players\n",
        "      soup = BeautifulSoup(directoryReponse.text, \"lxml\")\n",
        "      div_players = soup.find(\"div\", {\"id\": \"div_players\"})\n",
        "      table = div_players.find('tbody')\n",
        "      rows = table.find_all('tr')\n",
        "\n",
        "      # iterate through each player/row\n",
        "      for row in rows:\n",
        "        count += 1\n",
        "        playerStatsTable = []\n",
        "        isHoF = False\n",
        "        if (\"</a>*\" in str(row)):\n",
        "          isHoF = True\n",
        "\n",
        "        playerName = row.find('a').text\n",
        "        playerhref = row.find('a')[\"href\"]\n",
        "        playerLink = \"https://www.basketball-reference.com\" + playerhref\n",
        "        year_min = int(row.find(\"td\", {\"data-stat\": \"year_min\"}).text)\n",
        "        year_max = int(row.find(\"td\", {\"data-stat\": \"year_max\"}).text)\n",
        "\n",
        "        # visit player's link if year_min > 1980 and year_max < 2015, add player to players\n",
        "        if (year_min > 1968 and year_max < 2015):\n",
        "          playerResponse = requests.get(playerLink)\n",
        "          playerStatsTable.append(playerName)\n",
        "\n",
        "          if playerResponse.ok:\n",
        "            soup = BeautifulSoup(playerResponse.text, \"lxml\")\n",
        "            # take career average for now\n",
        "            div_per_game = soup.find(\"div\", {\"id\": \"div_per_game\"})\n",
        "            playerStats = div_per_game.find('tfoot').find('tr').find_all(\"td\")\n",
        "            playerStats = playerStats[4:29]\n",
        "\n",
        "            completeStats = True\n",
        "            hasEmptyStat = False\n",
        "\n",
        "            if (len(playerStats) == 25):\n",
        "              for stat in playerStats:\n",
        "                if not stat.text:\n",
        "                  hasEmptyStat = True\n",
        "                  break\n",
        "                else:\n",
        "                  playerStatsTable.append(float(stat.text))\n",
        "            else:\n",
        "              completeStats = False\n",
        "\n",
        "          print(isHoF)\n",
        "          if (isHoF):\n",
        "            playerStatsTable.append(1)\n",
        "            print(row)\n",
        "          else:\n",
        "            playerStatsTable.append(0)\n",
        "\n",
        "          if (completeStats and not hasEmptyStat):\n",
        "            playersStatsTable.append(playerStatsTable)"
      ],
      "metadata": {
        "id": "TW0qTGW7omnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.matrix(playersStatsTable))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBntLWTaBFyv",
        "outputId": "beaaddef-b54e-409e-b427-de66969daa69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Alaa Abdelnaby' '256.0' '53.0' ... '1.9' '5.7' '0']\n",
            " ['Kareem Abdul-Jabbar' '1560.0' '625.0' ... '3.0' '24.6' '1']\n",
            " ['Mahmoud Abdul-Rauf' '586.0' '336.0' ... '1.9' '14.6' '0']\n",
            " ...\n",
            " ['Sam Young' '249.0' '52.0' ... '1.2' '5.8' '0']\n",
            " ['Wang Zhizhi' '137.0' '1.0' ... '1.1' '4.4' '0']\n",
            " ['George Zídek' '135.0' '23.0' ... '1.8' '3.4' '0']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export data to Excel sheet\n",
        "df = pd.DataFrame(playersStatsTable)\n",
        "df.to_excel(excel_writer = \"NBAPlayersStats.xlsx\")"
      ],
      "metadata": {
        "id": "ygaWmSeLRs-F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import excel\n",
        "ogdf = pd.read_excel('NBAPlayersStats.xlsx')\n",
        "ogdf = ogdf.iloc[: , 1:]\n",
        "df = ogdf\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYryud79ef3L",
        "outputId": "3ac10c7a-99ed-4dab-883c-d4928c0c1ddc"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       0     1    2     3     4     5      6    7    8   \\\n",
            "0          Alaa Abdelnaby   256   53  12.5   2.4   4.8  0.502  0.0  0.0   \n",
            "1     Kareem Abdul-Jabbar  1560  625  36.8  10.2  18.1  0.559  0.0  0.0   \n",
            "2      Mahmoud Abdul-Rauf   586  336  26.7   6.0  13.6  0.442  0.8  2.3   \n",
            "3       Tariq Abdul-Wahad   236  145  20.4   3.1   7.3  0.417  0.1  0.3   \n",
            "4     Shareef Abdur-Rahim   830  704  34.8   6.5  13.9  0.472  0.2  0.6   \n",
            "...                   ...   ...  ...   ...   ...   ...    ...  ...  ...   \n",
            "1744       Korleone Young     3    0   5.0   1.7   3.3  0.500  0.3  1.3   \n",
            "1745        Michael Young    49    2   9.6   1.9   4.1  0.465  0.2  0.6   \n",
            "1746            Sam Young   249   52  15.9   2.2   5.1  0.442  0.2  0.7   \n",
            "1747          Wang Zhizhi   137    1   9.2   1.6   3.7  0.417  0.5  1.3   \n",
            "1748         George Zídek   135   23   9.8   1.2   2.9  0.408  0.0  0.0   \n",
            "\n",
            "         9   ...   17   18    19   20   21   22   23   24    25  26  \n",
            "0     0.000  ...  1.1  2.2   3.3  0.3  0.3  0.3  1.0  1.9   5.7   0  \n",
            "1     0.056  ...  2.4  7.6  11.2  3.6  0.9  2.6  2.7  3.0  24.6   1  \n",
            "2     0.354  ...  0.4  1.5   1.9  3.5  0.8  0.1  1.6  1.9  14.6   0  \n",
            "3     0.237  ...  1.2  2.1   3.3  1.1  0.8  0.4  1.3  2.1   7.8   0  \n",
            "4     0.297  ...  2.3  5.3   7.5  2.5  1.0  0.8  2.6  2.8  18.1   0  \n",
            "...     ...  ...  ...  ...   ...  ...  ...  ...  ...  ...   ...  ..  \n",
            "1744  0.250  ...  0.7  0.7   1.3  0.3  0.0  0.0  0.3  1.0   4.3   0  \n",
            "1745  0.296  ...  0.8  1.0   1.8  0.5  0.5  0.1  0.3  1.0   4.6   0  \n",
            "1746  0.280  ...  0.7  1.6   2.3  0.7  0.5  0.2  0.8  1.2   5.8   0  \n",
            "1747  0.385  ...  0.4  1.3   1.7  0.3  0.2  0.3  0.5  1.1   4.4   0  \n",
            "1748  0.250  ...  0.8  1.3   2.1  0.2  0.1  0.1  0.5  1.8   3.4   0  \n",
            "\n",
            "[1749 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## get Training and Testing ########\n",
        "y = df.iloc[: , 26:]\n",
        "X = df.iloc[: , 1:26]\n",
        "# drop stats Games Played & Games Started \n",
        "cols = [0,1]\n",
        "X.drop(X.columns[cols], axis=1, inplace=True)\n",
        "print(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "print(len(X_train),len(X_test), len(y_train), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9HrdzMvfp7O",
        "outputId": "67201897-4102-4ad7-bad7-36b6d20eda88"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        3     4     5      6    7    8      9     10    11     12  ...     16  \\\n",
            "0     12.5   2.4   4.8  0.502  0.0  0.0  0.000   2.4   4.8  0.503  ...  0.701   \n",
            "1     36.8  10.2  18.1  0.559  0.0  0.0  0.056  10.2  18.1  0.560  ...  0.721   \n",
            "2     26.7   6.0  13.6  0.442  0.8  2.3  0.354   5.2  11.3  0.460  ...  0.905   \n",
            "3     20.4   3.1   7.3  0.417  0.1  0.3  0.237   3.0   7.0  0.425  ...  0.703   \n",
            "4     34.8   6.5  13.9  0.472  0.2  0.6  0.297   6.4  13.2  0.480  ...  0.810   \n",
            "...    ...   ...   ...    ...  ...  ...    ...   ...   ...    ...  ...    ...   \n",
            "1744   5.0   1.7   3.3  0.500  0.3  1.3  0.250   1.3   2.0  0.667  ...  1.000   \n",
            "1745   9.6   1.9   4.1  0.465  0.2  0.6  0.296   1.8   3.6  0.491  ...  0.711   \n",
            "1746  15.9   2.2   5.1  0.442  0.2  0.7  0.280   2.1   4.4  0.468  ...  0.742   \n",
            "1747   9.2   1.6   3.7  0.417  0.5  1.3  0.385   1.0   2.4  0.435  ...  0.735   \n",
            "1748   9.8   1.2   2.9  0.408  0.0  0.0  0.250   1.2   2.9  0.409  ...  0.783   \n",
            "\n",
            "       17   18    19   20   21   22   23   24    25  \n",
            "0     1.1  2.2   3.3  0.3  0.3  0.3  1.0  1.9   5.7  \n",
            "1     2.4  7.6  11.2  3.6  0.9  2.6  2.7  3.0  24.6  \n",
            "2     0.4  1.5   1.9  3.5  0.8  0.1  1.6  1.9  14.6  \n",
            "3     1.2  2.1   3.3  1.1  0.8  0.4  1.3  2.1   7.8  \n",
            "4     2.3  5.3   7.5  2.5  1.0  0.8  2.6  2.8  18.1  \n",
            "...   ...  ...   ...  ...  ...  ...  ...  ...   ...  \n",
            "1744  0.7  0.7   1.3  0.3  0.0  0.0  0.3  1.0   4.3  \n",
            "1745  0.8  1.0   1.8  0.5  0.5  0.1  0.3  1.0   4.6  \n",
            "1746  0.7  1.6   2.3  0.7  0.5  0.2  0.8  1.2   5.8  \n",
            "1747  0.4  1.3   1.7  0.3  0.2  0.3  0.5  1.1   4.4  \n",
            "1748  0.8  1.3   2.1  0.2  0.1  0.1  0.5  1.8   3.4  \n",
            "\n",
            "[1749 rows x 23 columns]\n",
            "1399 350 1399 350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Over-sample data to resolve isHofF vs !isHofF class imabalance ##\n",
        "dfCopy = df\n",
        "class_count_0, class_count_1 = dfCopy.iloc[:,-1:].value_counts()\n",
        "\n",
        "# import library\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target variable\n",
        "X_ros, y_ros = ros.fit_resample(X, y)\n",
        "\n",
        "print('Original X shape', X.shape)\n",
        "print('Resample X shape', X_ros.shape)\n",
        "print('Original y shape', y.shape)\n",
        "print('Resample y shape', y_ros.shape)\n",
        "\n",
        "print(y.value_counts())\n",
        "print(y_ros.value_counts())\n",
        "\n",
        "# split ros\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_ros, y_ros,test_size=0.2)\n",
        "\n",
        "print(len(X_train),len(X_test), len(y_train), len(y_test))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRI3Bl94Mvt8",
        "outputId": "41657dcd-8623-4d3e-be2c-1b21b064016e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape (1749, 23)\n",
            "Resample X shape (3358, 23)\n",
            "Original y shape (1749, 1)\n",
            "Resample y shape (3358, 1)\n",
            "26\n",
            "0     1679\n",
            "1       70\n",
            "dtype: int64\n",
            "26\n",
            "0     1679\n",
            "1     1679\n",
            "dtype: int64\n",
            "2686 672 2686 672\n",
            "(2686, 23)\n",
            "(2686, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######## Train Neural Network Model ########\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Dropout\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "import keras\n",
        "\n",
        "# NN Model\n",
        "# NN_Model = Sequential()\n",
        "# NN_Model.add(Dense(1, input_shape=(24,), activation='sigmoid'))\n",
        "\n",
        "inputs = Input(shape=(23,), name=\"stats\")\n",
        "x = Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "x = Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "outputs = Dense(2, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "NN_Model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "NN_Model.compile(\n",
        "    # Optimizer\n",
        "    optimizer=optimizers.RMSprop(),\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "NN_Model.fit(X_train, y_train, epochs=200, batch_size=32)"
      ],
      "metadata": {
        "id": "qc0XeoWZrOga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6c4168-d520-4603-9fb5-ca03ffc4162e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "84/84 [==============================] - 1s 2ms/step - loss: 0.4175 - sparse_categorical_accuracy: 0.8313\n",
            "Epoch 2/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.2685 - sparse_categorical_accuracy: 0.8984\n",
            "Epoch 3/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.2141 - sparse_categorical_accuracy: 0.9203\n",
            "Epoch 4/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.2006 - sparse_categorical_accuracy: 0.9203\n",
            "Epoch 5/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1796 - sparse_categorical_accuracy: 0.9293\n",
            "Epoch 6/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1795 - sparse_categorical_accuracy: 0.9319\n",
            "Epoch 7/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1640 - sparse_categorical_accuracy: 0.9315\n",
            "Epoch 8/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1532 - sparse_categorical_accuracy: 0.9509\n",
            "Epoch 9/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1505 - sparse_categorical_accuracy: 0.9419\n",
            "Epoch 10/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1497 - sparse_categorical_accuracy: 0.9419\n",
            "Epoch 11/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9442\n",
            "Epoch 12/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1346 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 13/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1363 - sparse_categorical_accuracy: 0.9486\n",
            "Epoch 14/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9490\n",
            "Epoch 15/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9568\n",
            "Epoch 16/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1292 - sparse_categorical_accuracy: 0.9516\n",
            "Epoch 17/200\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.1203 - sparse_categorical_accuracy: 0.9546\n",
            "Epoch 18/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1220 - sparse_categorical_accuracy: 0.9538\n",
            "Epoch 19/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9605\n",
            "Epoch 20/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9631\n",
            "Epoch 21/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9643\n",
            "Epoch 22/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9594\n",
            "Epoch 23/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9657\n",
            "Epoch 24/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9594\n",
            "Epoch 25/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9672\n",
            "Epoch 26/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9672\n",
            "Epoch 27/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 28/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9669\n",
            "Epoch 29/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9657\n",
            "Epoch 30/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0884 - sparse_categorical_accuracy: 0.9684\n",
            "Epoch 31/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9684\n",
            "Epoch 32/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0844 - sparse_categorical_accuracy: 0.9739\n",
            "Epoch 33/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 34/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9717\n",
            "Epoch 35/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9736\n",
            "Epoch 36/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9739\n",
            "Epoch 37/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 38/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9717\n",
            "Epoch 39/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9777\n",
            "Epoch 40/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9762\n",
            "Epoch 41/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9758\n",
            "Epoch 42/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9747\n",
            "Epoch 43/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9777\n",
            "Epoch 44/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9751\n",
            "Epoch 45/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 46/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0682 - sparse_categorical_accuracy: 0.9780\n",
            "Epoch 47/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9736\n",
            "Epoch 48/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0662 - sparse_categorical_accuracy: 0.9773\n",
            "Epoch 49/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9765\n",
            "Epoch 50/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9784\n",
            "Epoch 51/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9754\n",
            "Epoch 52/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0663 - sparse_categorical_accuracy: 0.9765\n",
            "Epoch 53/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0572 - sparse_categorical_accuracy: 0.9821\n",
            "Epoch 54/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9806\n",
            "Epoch 55/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9777\n",
            "Epoch 56/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9803\n",
            "Epoch 57/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0527 - sparse_categorical_accuracy: 0.9795\n",
            "Epoch 58/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0538 - sparse_categorical_accuracy: 0.9821\n",
            "Epoch 59/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9792\n",
            "Epoch 60/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0528 - sparse_categorical_accuracy: 0.9840\n",
            "Epoch 61/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9773\n",
            "Epoch 62/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0533 - sparse_categorical_accuracy: 0.9818\n",
            "Epoch 63/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0460 - sparse_categorical_accuracy: 0.9855\n",
            "Epoch 64/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0550 - sparse_categorical_accuracy: 0.9832\n",
            "Epoch 65/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9806\n",
            "Epoch 66/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0529 - sparse_categorical_accuracy: 0.9829\n",
            "Epoch 67/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9806\n",
            "Epoch 68/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0462 - sparse_categorical_accuracy: 0.9859\n",
            "Epoch 69/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0492 - sparse_categorical_accuracy: 0.9840\n",
            "Epoch 70/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9825\n",
            "Epoch 71/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0453 - sparse_categorical_accuracy: 0.9855\n",
            "Epoch 72/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0470 - sparse_categorical_accuracy: 0.9840\n",
            "Epoch 73/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0416 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 74/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9836\n",
            "Epoch 75/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0399 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 76/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0388 - sparse_categorical_accuracy: 0.9851\n",
            "Epoch 77/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0422 - sparse_categorical_accuracy: 0.9851\n",
            "Epoch 78/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9885\n",
            "Epoch 79/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0431 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 80/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9859\n",
            "Epoch 81/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0427 - sparse_categorical_accuracy: 0.9844\n",
            "Epoch 82/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9873\n",
            "Epoch 83/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9855\n",
            "Epoch 84/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0395 - sparse_categorical_accuracy: 0.9885\n",
            "Epoch 85/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 86/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9862\n",
            "Epoch 87/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 88/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 89/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 90/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0353 - sparse_categorical_accuracy: 0.9888\n",
            "Epoch 91/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9903\n",
            "Epoch 92/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9881\n",
            "Epoch 93/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 94/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0361 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 95/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9885\n",
            "Epoch 96/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0295 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 97/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0284 - sparse_categorical_accuracy: 0.9899\n",
            "Epoch 98/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9885\n",
            "Epoch 99/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9870\n",
            "Epoch 100/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0323 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 101/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0304 - sparse_categorical_accuracy: 0.9885\n",
            "Epoch 102/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 103/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9918\n",
            "Epoch 104/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9903\n",
            "Epoch 105/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9907\n",
            "Epoch 106/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0260 - sparse_categorical_accuracy: 0.9899\n",
            "Epoch 107/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 108/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0287 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 109/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9885\n",
            "Epoch 110/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 111/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 112/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0267 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 113/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0270 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 114/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9933\n",
            "Epoch 115/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 116/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9929\n",
            "Epoch 117/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9911\n",
            "Epoch 118/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 119/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.9896\n",
            "Epoch 120/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9929\n",
            "Epoch 121/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 122/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9929\n",
            "Epoch 123/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0191 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 124/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 125/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9929\n",
            "Epoch 126/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 127/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0213 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 128/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 129/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 130/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 131/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 132/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0135 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 133/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9929\n",
            "Epoch 134/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9933\n",
            "Epoch 135/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0180 - sparse_categorical_accuracy: 0.9944\n",
            "Epoch 136/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9933\n",
            "Epoch 137/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0290 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 138/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 139/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0347 - sparse_categorical_accuracy: 0.9892\n",
            "Epoch 140/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 141/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9940\n",
            "Epoch 142/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 143/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 144/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 145/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 146/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 147/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 148/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9922\n",
            "Epoch 149/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9940\n",
            "Epoch 150/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 151/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9944\n",
            "Epoch 152/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 153/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 154/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 155/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 156/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0177 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 157/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0122 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 158/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0118 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 159/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0235 - sparse_categorical_accuracy: 0.9914\n",
            "Epoch 160/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 161/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0157 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 162/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 163/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 164/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 165/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0140 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 166/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 167/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 168/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 169/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 170/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 171/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0165 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 172/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 173/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0250 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 174/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 175/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 176/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 177/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 178/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 179/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 180/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0096 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 181/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 182/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 183/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 184/200\n",
            "84/84 [==============================] - 0s 3ms/step - loss: 0.0186 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 185/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 186/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 187/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0177 - sparse_categorical_accuracy: 0.9944\n",
            "Epoch 188/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9959\n",
            "Epoch 189/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9970\n",
            "Epoch 190/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 191/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9944\n",
            "Epoch 192/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 193/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 194/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 195/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0063 - sparse_categorical_accuracy: 0.9981\n",
            "Epoch 196/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 197/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9963\n",
            "Epoch 198/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 199/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 200/200\n",
            "84/84 [==============================] - 0s 2ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9974\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20ceacb790>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "score = NN_Model.evaluate(X_test, y_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "pred = NN_Model.predict(X_test)[:,1]\n",
        "pred[pred > 0.5] = 1\n",
        "pred[pred <= 0.5] = 0\n",
        " \n",
        "#calculating precision and reall\n",
        "precision = precision_score(y_test, pred)\n",
        "recall = recall_score(y_test, pred)\n",
        "print(\"precision: \")\n",
        "print(precision)\n",
        "print(\"recall: \")\n",
        "print(recall)\n",
        "confusion_matrix(y_test, pred)"
      ],
      "metadata": {
        "id": "e3p1i3ljqGrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f826f37-9978-438c-bc83-e9eec4c46d9a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 2ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9866\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "precision: \n",
            "0.9736070381231672\n",
            "recall: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[331,   9],\n",
              "       [  0, 332]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using customized current players\n",
        "LukaDoncic = \"33.8\t9.0\t19.7\t.457\t2.8\t8.2\t.337\t6.2\t11.5\t.543\t.528\t5.6\t7.6\t.737\t1.0\t7.5\t8.5\t8.0\t1.1\t0.4\t4.1\t2.2 26.4\"\n",
        "KobeBryant = \"36.1\t8.7\t19.5\t.447\t1.4\t4.1\t.329\t7.3\t15.3\t.479\t.482\t6.2\t7.4\t.837\t1.1\t4.1\t5.2\t4.7\t1.4\t0.5\t3.0\t2.5\t25.0\"\n",
        "ShaqOneal = \"34.7\t9.4\t16.1\t.582\t0.0\t0.0\t.045\t9.4\t16.1\t.583\t.582\t4.9\t9.3\t.527\t3.5\t7.4\t10.9\t2.5\t0.6\t2.3\t2.7\t3.4\t23.7\"\n",
        "CarmeloAnthony = \"34.5\t8.0\t18.0\t.447\t1.4\t3.9\t.355\t6.7\t14.1\t.472\t.485\t5.0\t6.2\t.814\t1.6\t4.6\t6.2\t2.7\t1.0\t0.5\t2.4\t2.8\t22.5\"\n",
        "JRSmith = \"26.9\t4.5\t10.7\t.419\t2.0\t5.3\t.373\t2.5\t5.4\t.463\t.511\t1.5\t2.0\t.733\t0.5\t2.6\t3.1\t2.1\t1.0\t0.2\t1.3\t2.2\t12.4\"\n",
        "LeBronJames = \"38.2\t9.9\t19.6\t.505\t1.6\t4.5\t.346\t8.3\t15.1\t.552\t.545\t5.7\t7.8\t.734\t1.2\t6.3\t7.5\t7.4\t1.6\t0.8\t3.5\t1.8\t27.1\"\n",
        "RJBarret = \"33.5\t6.3\t15.1\t.418\t1.6\t4.6\t.357\t4.7\t10.5\t.445\t.472\t3.3\t4.7\t.697\t0.9\t4.6\t5.6\t2.9\t0.8\t0.3\t2.1\t2.3\t17.5\"\n",
        "JeremyLin = \"25.5\t3.9\t9.1\t.433\t0.9\t2.7\t.342\t3.0\t6.3\t.473\t.485\t2.8\t3.5\t.809\t0.4\t2.4\t2.8\t4.3\t1.1\t0.4\t2.3\t2.2\t11.6\"\n",
        "DerrickRose = \"31.7\t7.1\t15.6\t.457\t0.8\t2.6\t.316\t6.3\t13.0\t.485\t.483\t3.1\t3.8\t.830\t0.8\t2.5\t3.3\t5.4\t0.8\t0.3\t2.5\t1.3\t18.2\"\n",
        "KristapsPorzingis = \"30.8\t6.8\t15.3\t.444\t1.8\t5.0\t.353\t5.0\t10.2\t.488\t.502\t3.6\t4.4\t.820\t1.7\t6.1\t7.9\t1.6\t0.7\t1.9\t1.6\t3.0\t18.9\"\n",
        "EvanFournier = \"28.6\t5.1\t11.5\t.445\t2.0\t5.3\t.381\t3.1\t6.3\t.499\t.532\t2.0\t2.5\t.798\t0.4\t2.3\t2.7\t2.6\t0.9\t0.2\t1.6\t2.4\t14.3\"\n",
        "ImmanuelQuickley = \"21.4\t3.6\t9.2\t.393\t1.8\t4.9\t.365\t1.8\t4.3\t.426\t.491\t2.3\t2.6\t.885\t0.4\t2.3\t2.7\t2.8\t0.6\t0.1\t1.1\t2.0\t11.4\"\n",
        "JalenBrunson = \"24.7\t4.6\t9.3\t.494\t1.0\t2.7\t.373\t3.6\t6.6\t.544\t.548\t1.6\t2.0\t.800\t0.4\t2.6\t3.0\t3.7\t0.6\t0.0\t1.3\t1.7\t11.9\"\n",
        "\n",
        "playerNames = [\n",
        "    \"Luka Doncic\",\n",
        "    \"Carmelo Anthony\",\n",
        "    \"JR Smith\",\n",
        "    \"LeBron James\",\n",
        "    \"Jeremy Lin\",\n",
        "    \"Kristaps Porzingis\",\n",
        "    \"Jalen Brunson\",\n",
        "    \"Evan Fournier\",\n",
        "    \"Immanuel Quickley\",\n",
        "    \"Julius Randle\",\n",
        "    \"Cam Reddish\",\n",
        "    \"Derrick Rose\",\n",
        "    \"Obi Toppin\",\n",
        "    \"Stephen Curry\",\n",
        "    \"Joakim Noah\",\n",
        "    \"Draymond Green\",\n",
        "    \"JaVale McGee\",\n",
        "    \"Danilo Gallinari\",\n",
        "    \"De'Aaron Fox\",\n",
        "    \"Vince Carter\",\n",
        "    \"Travis Knight\",\n",
        "    \"Patrick Beverley\",\n",
        "    \"José Calderón\",\n",
        "    \"Tyson Chandler\",\n",
        "    \"Amar'e Stoudemire\"\n",
        "]\n",
        "\n",
        "playersStats = [\n",
        "    \"33.8\t9.0\t19.7\t.457\t2.8\t8.2\t.337\t6.2\t11.5\t.543\t.528\t5.6\t7.6\t.737\t1.0\t7.5\t8.5\t8.0\t1.1\t0.4\t4.1\t2.2 26.4\",\n",
        "    \"34.5\t8.0\t18.0\t.447\t1.4\t3.9\t.355\t6.7\t14.1\t.472\t.485\t5.0\t6.2\t.814\t1.6\t4.6\t6.2\t2.7\t1.0\t0.5\t2.4\t2.8\t22.5\",\n",
        "    \"26.9\t4.5\t10.7\t.419\t2.0\t5.3\t.373\t2.5\t5.4\t.463\t.511\t1.5\t2.0\t.733\t0.5\t2.6\t3.1\t2.1\t1.0\t0.2\t1.3\t2.2\t12.4\",\n",
        "    \"38.2\t9.9\t19.6\t.505\t1.6\t4.5\t.346\t8.3\t15.1\t.552\t.545\t5.7\t7.8\t.734\t1.2\t6.3\t7.5\t7.4\t1.6\t0.8\t3.5\t1.8\t27.1\",\n",
        "    \"25.5\t3.9\t9.1\t.433\t0.9\t2.7\t.342\t3.0\t6.3\t.473\t.485\t2.8\t3.5\t.809\t0.4\t2.4\t2.8\t4.3\t1.1\t0.4\t2.3\t2.2\t11.6\",\n",
        "    \"30.8\t6.8\t15.3\t.444\t1.8\t5.0\t.353\t5.0\t10.2\t.488\t.502\t3.6\t4.4\t.820\t1.7\t6.1\t7.9\t1.6\t0.7\t1.9\t1.6\t3.0\t18.9\",\n",
        "    \"24.7\t4.6\t9.3\t.494\t1.0\t2.7\t.373\t3.6\t6.6\t.544\t.548\t1.6\t2.0\t.800\t0.4\t2.6\t3.0\t3.7\t0.6\t0.0\t1.3\t1.7\t11.9\",\n",
        "    \"28.6\t5.1\t11.5\t.445\t2.0\t5.3\t.381\t3.1\t6.3\t.499\t.532\t2.0\t2.5\t.798\t0.4\t2.3\t2.7\t2.6\t0.9\t0.2\t1.6\t2.4\t14.3\",\n",
        "    \"21.4\t3.6\t9.2\t.393\t1.8\t4.9\t.365\t1.8\t4.3\t.426\t.491\t2.3\t2.6\t.885\t0.4\t2.3\t2.7\t2.8\t0.6\t0.1\t1.1\t2.0\t11.4\",\n",
        "    \"31.2\t6.5\t13.9\t.472\t0.9\t2.6\t.332\t5.7\t11.3\t.504\t.503\t3.8\t5.1\t.743\t2.0\t7.3\t9.3\t3.6\t0.7\t0.5\t2.7\t3.1\t17.7\",\n",
        "    \"24.9\t3.6\t9.2\t.387\t1.4\t4.2\t.325\t2.2\t5.0\t.439\t.461\t2.0\t2.4\t.841\t0.6\t2.6\t3.2\t1.3\t1.1\t0.4\t1.4\t2.0\t10.5\",\n",
        "    \"31.7\t7.1\t15.6\t.457\t0.8\t2.6\t.316\t6.3\t13.0\t.485\t.483\t3.1\t3.8\t.830\t0.8\t2.5\t3.3\t5.4\t0.8\t0.3\t2.5\t1.3\t18.2\",\n",
        "    \"14.3\t2.6\t5.1\t.521\t0.6\t1.9\t.307\t2.1\t3.2\t.647\t.578\t0.8\t1.1\t.753\t0.7\t2.3\t3.0\t0.8\t0.3\t0.4\t0.6\t1.2\t6.7\",\n",
        "    \"34.3\t8.3\t17.6\t.473\t3.8\t8.8\t.428\t4.5\t8.8\t.520\t.581\t3.9\t4.3\t.908\t0.7\t4.0\t4.6\t6.5\t1.7\t0.2\t3.1\t2.4\t24.3\",\n",
        "    \"27.7\t3.3\t6.8\t.491\t0.0\t0.0\t.000\t3.3\t6.8\t.493\t.491\t2.1\t2.9\t.700\t3.2\t5.8\t9.0\t2.8\t0.8\t1.3\t1.7\t2.8\t8.8\",\n",
        "    \"28.5\t3.2\t7.2\t.441\t0.8\t2.6\t.315\t2.3\t4.6\t.514\t.499\t1.5\t2.1\t.712\t1.1\t5.8\t6.9\t5.4\t1.4\t1.0\t2.2\t2.8 8.7\",\n",
        "    \"17.0\t3.4\t5.9\t.576\t0.0\t0.1\t.182\t3.4\t5.8\t.582\t.577\t1.1\t1.9\t.605\t1.9\t3.4\t5.3\t0.4\t0.4\t1.5\t1.0\t2.2\t8.0\",\n",
        "    \"29.9\t4.7\t11.1\t.428\t2.0\t5.1\t.382\t2.8\t6.0\t.467\t.516\t4.1\t4.7\t.877\t0.7\t4.1\t4.8\t1.9\t0.7\t0.4\t1.2\t1.8\t15.6\",\n",
        "    \"32.1\t7.0\t15.3\t.462\t1.1\t3.5\t.320\t5.9\t11.7\t.504\t.499\t3.9\t5.3\t.725\t0.5\t3.0\t3.5\t6.2\t1.3\t0.4\t2.8\t2.7\t19.1\",\n",
        "    \"30.1\t6.0\t13.8\t.435\t1.5\t4.0\t.371\t4.5\t9.8\t.462\t.489\t3.1\t3.9\t.798\t1.1\t3.2\t4.3\t3.1\t1.0\t0.6\t1.7\t2.6\t16.7\",\n",
        "    \"12.3\t1.4\t3.2\t.438\t0.0\t0.2\t.259\t1.4\t3.1\t.447\t.444\t0.6\t0.8\t.696\t1.2\t1.9\t3.1\t0.6\t0.4\t0.6\t0.7\t2.2\t3.4\",\n",
        "    \"27.4\t3.1\t7.5\t.414\t1.6\t4.2\t.378\t1.5\t3.3\t.460\t.520\t1.1\t1.4\t.756\t1.1\t3.1\t4.3\t3.5\t1.1\t0.5\t1.3\t3.1\t8.8\",\n",
        "    \"26.4\t3.4\t7.2\t.472\t1.0\t2.5\t.407\t2.4\t4.7\t.507\t.543\t1.0\t1.2\t.873\t0.3\t2.1\t2.4\t5.8\t0.8\t0.1\t1.5\t1.6\t8.9\",\n",
        "    \"27.3\t3.1\t5.1\t.597\t0.0\t0.0\t.000\t3.1\t5.1\t.598\t.597\t2.1\t3.2\t.644\t3.0\t6.0\t9.0\t0.8\t0.5\t1.2\t1.4\t2.8\t8.2\",\n",
        "    \"1.0\t7.0\t13.0\t.537\t0.0\t0.2\t.236\t7.0\t12.9\t.540\t.538\t4.9\t6.4\t.761\t2.4\t5.4\t7.8\t1.2\t0.8\t1.2\t2.3\t3.2\t18.9\",\n",
        "]\n",
        "\n",
        "for i in range(0, len(playerNames)):\n",
        "  playerStats = playersStats[i]\n",
        "  print(playerNames[i] + \": \" + predictPlayer(convertToDf(playerStats)))\n",
        "\n",
        "def convertToDf(playerStats):\n",
        "  playerStats = playerStats.split()\n",
        "  playerStats = np.array(playerStats)\n",
        "  playerStats = pd.DataFrame(data=playerStats).T.astype(float)\n",
        "  return playerStats\n",
        "\n",
        "def predictPlayer(playerStats):\n",
        "  prediction = NN_Model.predict(playerStats, verbose=0).item(1)\n",
        "  if (prediction > 0.5):\n",
        "    return \"Future Hall of Famer\"\n",
        "  else:\n",
        "    return \"Not Future Hall of Famer\""
      ],
      "metadata": {
        "id": "AZN0AQNhhMz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k nearest neighbors\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "knn_model = KNeighborsRegressor(n_neighbors=2)\n",
        "knn_model.fit(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TasVgwkDSUQC",
        "outputId": "0728cc90-c7aa-4102-a674-4fe719665e45"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(n_neighbors=2)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn_model.score(X_test, y_test))\n",
        "knn_model.predict(playerStats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKF2_NBnSkGX",
        "outputId": "de85cca1-0764-4385-8ad3-745f627ec3bd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9806540764624597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}